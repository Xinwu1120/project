# project
A Joint Visual-Semantic Robustness Framework Under Image-Side Adversarial Attacks
This thesis proposes a multimodal confrontational defense framework to enhance the robustness of the customized CLIP model. First of all, we introduce the overall structure of the unified assembly line, focusing on how to integrate purification and confrontation prompt learning into the phased optimization strategy. Next, we introduce in detail the Transformer-based purifier and its potential alignment mechanism, including the random transformation mechanism, the pixel-level reconstruction target, and the semantic feature alignment in the shared embedded space. We then describe the few-shot adversarial prompt learning module, covering prompt initialization, dual-path training under natural and adversarial views, and visual consistency regularization.Finally, we formulate the unified dual-path objective and present a complete optimization strategy that jointly balances clean accuracy, adversarial robustness, and cross-modal semantic consistency. These components form a unified training pipeline with staged optimization—initially focusing on pixel-level reconstruction and then progressively integrating latent alignment with adversarial supervision—to yield a highly robust vision–language model. Unless otherwise specified, we set the perturbation budget to $\epsilon = 1/255$, the step size to $\alpha = 1/255$, and use 100 attack iterations for evaluation.
